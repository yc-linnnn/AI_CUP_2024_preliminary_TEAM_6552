# TEAM 6552

## Features

- **1. Running with full Data Processing Pipeline from PDF Files**:
  - This pipeline includes:
    - **PDF Text Extraction**: Extracts text from PDFs using pdfPlumber, with OCR-enabled extraction specifically for finance documents.
    - **Data Cleaning**: Cleans insurance and finance text according to domain-specific rules for improved accuracy.
    - **Chunking**: Splits large texts into smaller, manageable chunks to enhance retrieval performance.
    - **Title Extraction**: Uses a LLaMA model to extract document titles for more precise retrieval (pre-built titles can also be used).
    - **Semantic Retrieval**: Implements a language model-based reranker to identify and return the most relevant file in response to a query.

- **2. Running from Pre-Built Dataset**:
  - A pre-built dataset is available, generated by the same data processing pipeline as described in Step 1.

**Recommendation**: For efficiency, itâ€™s recommended to use the pre-built dataset to save processing time.

## Prerequisites

- Python 3.11.8
- Require pytesseract system package
- Required packages listed in `requirements.txt`, including:
  - `pymupdf`
  - `pytesseract`
  - `pdf2image`
  - `pdfplumber`
  - `torch==2.3.1`  
  - (Maybe it works on newer versions but mine is 2.3.1 and I have no time to test it out)
  - `transformers`
  - `tqdm`


## Usage

### Command-Line Arguments

Run the script by providing the following arguments:

| Argument                        | Type    | Description                                                                                                           |
|---------------------------------|---------|-----------------------------------------------------------------------------------------------------------------------|
| `--question_path`               | String  | Path to the JSON file containing the questions.                                                                       |
| `--source_path`                 | String  | Path to the directory containing reference documents (`insurance`, `finance`, and `faq`).                             |
| `--output_path`                 | String  | Path where the output JSON will be saved.                                                                             |
| `--use_pre_built_dataset`       | Boolean | If included, uses pre-built chunks to save processing time.                                                                |
| `--use_pre_built_document_titles` | Boolean | Only used if `use_pre_built_dataset` is `False`. If included, uses pre-built titles instead of extracting them anew.      |

### Running the Script

Example:

```bash
python main.py --question_path ...questions.json --source_path .../reference --output_path ....pred_retrieve.json --use_pre_built_dataset

Again, it is recommened to use -use_pre_built_dataset to save time or it would probably spend 30 extra minutes for processing data.